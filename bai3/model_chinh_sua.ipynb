{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMEg/JeTd3r86Hgs3H6TbeO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Toan02Ky-UIT/CodeProject/blob/main/model_chinh_sua.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kx8DIDOH-n3d",
        "outputId": "8167afa1-e4c0-4f8f-d187-4692178412b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "from lightgbm import LGBMRegressor\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "df = pd.read_csv('/gdrive/MyDrive/Project/Bai2/annonimized.csv')\n",
        "diem_ck = pd.read_csv('/gdrive/MyDrive/Project/Bai3/ck-public.csv')\n"
      ],
      "metadata": {
        "id": "vrN3nzFU_naB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = df.rename(columns={\n",
        "    \"concat('it001',`assignment_id`)\": \"assignment_id\",\n",
        "    \"concat('it001',`problem_id`)\": \"problem_id\",\n",
        "    \"concat('it001', username)\": \"username\",\n",
        "    \"concat('it001',`language_id`)\": \"language_id\",\n",
        "})\n"
      ],
      "metadata": {
        "id": "eWAtv5lGAUj9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['created_at'] = df['created_at'].astype(str)\n",
        "\n",
        "df['day_month'] = df['created_at'].str.extract(r'(\\d{2}-\\d{2})')[0]\n",
        "\n",
        "def day_of_year(day_month):\n",
        "    try:\n",
        "        if pd.isna(day_month):\n",
        "            return None\n",
        "        month, day = map(int, day_month.split('-'))\n",
        "        days_in_months = [0, 31, 59, 90, 120, 151, 181, 212, 243, 273, 304, 334]\n",
        "        return days_in_months[month - 1] + day\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "\n",
        "df['day_in_year'] = df['day_month'].apply(day_of_year)\n"
      ],
      "metadata": {
        "id": "lhTLKhrnziWu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "def safe_parse_judgement(j):\n",
        "    try:\n",
        "        if pd.isna(j):\n",
        "            return {}\n",
        "        if isinstance(j, dict):\n",
        "            return j\n",
        "        # Attempt to load JSON, handling potential errors\n",
        "        parsed_judgement = json.loads(j)\n",
        "        # Check if the parsed result is a dictionary\n",
        "        if isinstance(parsed_judgement, dict):\n",
        "            return parsed_judgement\n",
        "        else:\n",
        "            # If not a dictionary, return an empty dictionary\n",
        "            return {}\n",
        "    except:\n",
        "        # Return an empty dictionary for any parsing errors\n",
        "        return {}\n",
        "\n",
        "df['judgement_parsed'] = df['judgement'].apply(safe_parse_judgement)\n",
        "\n",
        "# Lấy các feature từ judgement\n",
        "df['has_fatal_error'] = df['judgement_parsed'].apply(\n",
        "    lambda x: any('fatal error' in k.lower() for k in x.get('verdicts', {}) if isinstance(x.get('verdicts', {}), dict) and isinstance(k, str))\n",
        ")\n",
        "\n",
        "df['verdict_WRONG_count'] = df['judgement_parsed'].apply(\n",
        "    lambda x: x.get('verdicts', {}).get('WRONG', 0) if isinstance(x.get('verdicts', {}), dict) else 0\n",
        ")\n",
        "\n",
        "df['time_limit_exceeded_count'] = df['judgement_parsed'].apply(\n",
        "    lambda x: x.get('verdicts', {}).get('Time Limit Exceeded', 0) if isinstance(x.get('verdicts', {}), dict) else 0\n",
        ")"
      ],
      "metadata": {
        "id": "SON4punj01ec"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['final_score'] = df['pre_score'] * df['coefficient'] / 10000\n",
        "\n",
        "# Encode language\n",
        "le = LabelEncoder()\n",
        "df['language_id_encoded'] = le.fit_transform(df['language_id'])\n"
      ],
      "metadata": {
        "id": "9mPo5TFBXQ5Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_df = df.groupby('username').agg(\n",
        "    total_submissions=('problem_id', 'count'),\n",
        "    final_submissions=('is_final', 'sum'),\n",
        "    distinct_problems=('problem_id', 'nunique'),\n",
        "    max_score_problems=('final_score', lambda x: (x == 10).sum()),\n",
        "    mean_final_score=('final_score', 'mean'),\n",
        "    mean_coefficient=('coefficient', 'mean'),\n",
        "    compilation_error_rate=('status', lambda x: (x == 'Compilation Error').mean()),\n",
        "    syntax_error_rate=('status', lambda x: (x == 'Syntax Error').mean()),\n",
        "    pending_rate=('status', lambda x: (x == 'Pending').mean()),\n",
        "    has_fatal_error=('has_fatal_error', 'max'),\n",
        "    verdict_WRONG_count=('verdict_WRONG_count', 'sum'),\n",
        "    time_limit_exceeded_count=('time_limit_exceeded_count', 'sum'),\n",
        "    used_multiple_languages=('language_id', 'nunique'),\n",
        "    dominant_language=('language_id_encoded', lambda x: x.mode().iloc[0] if not x.mode().empty else -1),\n",
        "    mean_day=('day_in_year', 'mean'),\n",
        "    std_day=('day_in_year', 'std')\n",
        ").reset_index()\n",
        "\n",
        "# Thêm active days\n",
        "first_last_time = df.groupby('username').agg(\n",
        "    first_day=('day_in_year', 'min'),\n",
        "    last_day=('day_in_year', 'max')\n",
        ")\n",
        "first_last_time['active_days'] = first_last_time['last_day'] - first_last_time['first_day']\n",
        "first_last_time['active_days'] = first_last_time['active_days'].apply(lambda x: x + 365 if x < 0 else x)\n",
        "\n",
        "feature_df = feature_df.merge(first_last_time[['active_days']], on='username', how='left')"
      ],
      "metadata": {
        "id": "P-FbauqATlPg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unique ngày hoạt động\n",
        "active_day_count = df.groupby('username')['day_in_year'].nunique().rename('unique_active_days')\n",
        "feature_df = feature_df.merge(active_day_count, on='username', how='left')\n",
        "\n",
        "# Thời điểm nộp bài trung bình normalized\n",
        "feature_df['mean_day_normalized'] = feature_df['mean_day'] / 365\n",
        "\n",
        "# Tỉ lệ nộp bài muộn (sau ngày thứ 270)\n",
        "late_submissions = df[df['day_in_year'] > 270].groupby('username').size().rename('late_submissions')\n",
        "feature_df = feature_df.merge(late_submissions, on='username', how='left')\n",
        "feature_df['late_submissions'] = feature_df['late_submissions'].fillna(0)\n",
        "feature_df['late_submission_rate'] = feature_df['late_submissions'] / feature_df['total_submissions']\n",
        "\n",
        "# Số bài final nhưng không đạt điểm tối đa\n",
        "final_below_max = df[(df['is_final'] == 1) & (df['final_score'] < 10)].groupby('username').size().rename('final_below_max_count')\n",
        "feature_df = feature_df.merge(final_below_max, on='username', how='left')\n",
        "feature_df['final_below_max_count'] = feature_df['final_below_max_count'].fillna(0)\n",
        "\n",
        "# Tỉ lệ bài đạt điểm tối đa\n",
        "feature_df['max_score_rate'] = feature_df['max_score_problems'] / feature_df['distinct_problems']\n",
        "\n",
        "# Có dùng nhiều hơn 1 ngôn ngữ không\n",
        "feature_df['uses_multiple_languages_flag'] = (feature_df['used_multiple_languages'] > 1).astype(int)\n",
        "\n",
        "# Tổng số lỗi\n",
        "feature_df['total_errors'] = (\n",
        "    feature_df['compilation_error_rate'] * feature_df['total_submissions'] +\n",
        "    feature_df['syntax_error_rate'] * feature_df['total_submissions'] +\n",
        "    feature_df['verdict_WRONG_count'] +\n",
        "    feature_df['time_limit_exceeded_count'] +\n",
        "    feature_df['has_fatal_error']\n",
        ")\n",
        "\n",
        "# Tỉ lệ lỗi\n",
        "feature_df['error_rate'] = feature_df['total_errors'] / feature_df['total_submissions']\n",
        "\n",
        "# Trung bình số lần nộp mỗi bài\n",
        "feature_df['submissions_per_problem'] = feature_df['total_submissions'] / feature_df['distinct_problems']\n"
      ],
      "metadata": {
        "id": "nwQ7rxTI35nO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_df = feature_df.merge(diem_ck.rename(columns={'hash': 'username', 'CK': 'target'}), on='username', how='left')\n",
        "\n",
        "feature_df['target'] = feature_df['target'].astype(str).str.replace('\\xa0', '', regex=True).str.strip()\n",
        "feature_df['target'] = pd.to_numeric(feature_df['target'], errors='coerce')\n",
        "\n",
        "# Train test split\n",
        "train_df = feature_df[feature_df['target'].notnull()]\n",
        "test_df = feature_df[feature_df['target'].isnull()]\n",
        "\n",
        "X = train_df.drop(columns=['username', 'target'])\n",
        "y = train_df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "dV0gpk30z8LZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestRegressor(random_state=42, max_depth=10, min_samples_split=13, n_estimators=91)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# B13. Đánh giá\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(f'R² trên tập test: {r2:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a__JGzNL2gzS",
        "outputId": "3c1e7583-9cae-4f4f-f8a9-9be417b45077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² trên tập test: 0.2601\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cat_model = CatBoostRegressor(\n",
        "    iterations=500,\n",
        "    learning_rate=0.05,\n",
        "    depth=6,\n",
        "    verbose=0,\n",
        "    random_seed=42\n",
        ")\n",
        "\n",
        "cat_model.fit(X_train, y_train)\n",
        "y_pred_cat = cat_model.predict(X_test)\n",
        "r2_cat = r2_score(y_test, y_pred_cat)\n",
        "print(f'R² CatBoost: {r2_cat:.4f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uQL1TNOt2h-J",
        "outputId": "9ca2c0cb-696a-48a4-c109-87a0ce14f5df"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² CatBoost: 0.2761\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_pred = (y_pred + y_pred_cat) / 2\n",
        "\n",
        "r2 = r2_score(y_test, avg_pred)\n",
        "print(f\"R² của Averaging: {r2:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lxNfm6q32j2E",
        "outputId": "4d302bb3-e435-4301-ac9b-177ea8dee352"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R² của Averaging: 0.2874\n"
          ]
        }
      ]
    }
  ]
}
